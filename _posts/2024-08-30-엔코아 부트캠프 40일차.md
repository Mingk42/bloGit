## 대제목

오늘은 간단한 머신러닝 프로그램을 만들어 보았다.

![image](https://github.com/user-attachments/assets/32aa1b44-cbaf-46ff-81ff-31c2e0a3218c)

위 그림과 같이 간단한 머신러닝을 FastAPI에 적용하여, 무게와 길이를 보내면 어떤 물고기인지 반환하는 API를 만드는 것이 최종 목표이다.

#### FastAPI로 기본 뼈대 만들기

먼저 FastAPI로 요청을 보내면 응답을 받을 수 있는 기본 뼈대를 구축하였다.

FastAPI의 사용법은 전에도 학습한 적이 있지만 [docs](https://fastapi.tiangolo.com/ko/)를 보고 따라가면 쉽게 만들 수 있다.

```bash
$ pdm init
$ pdm add fastapi
$ pdm add "uvicorn[standard]"
$ vi src/pkg/main.py
```
###### main.py
```python
from typing import Union

from fastapi import FastAPI

app = FastAPI()


@app.get("/")
def read_root():
    return {"Hello": "World"}


@app.get("/items/{item_id}")
def read_item(item_id: int, q: Union[str, None] = None):
    return {"item_id": item_id, "q": q}

@app.get("/fish")
def fish(length:float, weight:float):
    """
    어종 판별기

    Args:
     - length(int): 물고기 길이(cm)
     - weight(int): 물고기 무게(g)

    Return
     - dict, 물고기의 종류를 담은 딕셔너리
    """

    if length>=30:
        pred="도미"
    else:
        pred="빙어"


    return {
            "prediction":pred,
            "length":length,
            "weight":weight
            }
```

기본 예제에 우리가 최종 목표로 하는 fish함수를 추가해주었다. 아직은 학습된 모델이 없기 때문에 길이가 30cm 이상이면 도미 그 외에는 빙어로 예측값을 반환해주었다.

#### docker에 FastAPI 띄우기

그 다음에는 만들어진 FastAPI를 docker container로 띄워보았다. 이는 최종목표인 fly.io에 Dockerfile로 배포를 할 것이기 떄문에 작성된 Dockerfile이 잘 작성되었는지 확인하는 역할을 할 수 있고 FastAPI가 잘 동작하는지도 확인해 볼 수 있다. docker에서 잘 동작한다면 fly.io에서도 잘 동작할 것이라고 가정할 수 있다는 것이다.

아래와 같이 Dockerfile을 작성했다.
###### Dockerfile
```
FROM python:3.9     # Base Image, 어떤 image를 기반으로 docker image를 생성할 것인지 지정해준다.

WORKDIR /code       # working directory, 말 그대로 어떤 디렉토리에서 작업을 수행하는지 지정해준다.

COPY . /code        # Dockerfile이 위치한 디렉토리의 모든 파일과 디렉토리를 docker image의 /code로 복사한다. 

# docker container가 생성될 때 실행되는 명령. 여러 번 실행 가능하다.
RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

# RUN과 같이 container가 생성될 때 실행되는 명령이지만, 한 번만 실행가능하다. 서버 구동에 쓰인다.
CMD ["uvicorn", "src.fishmlserv.main:app", "--host", "0.0.0.0", "--port", "8080"]
```
Dockerfile이 작성된 이후 해당 파일을 이용하여 docker image를 생성해보았다.
```bash
$ sudo docker build -t fishmlserv:0.4.0 .     # -t  tag를 지정할 수 있다. 
```
해당 명령에서 `.`은 Dockerfile이 위치한 경로를 의미한다.

```bash
$ sudo docker images
REPOSITORY   TAG       IMAGE ID       CREATED        SIZE
fishmlserv   0.4.0     c249a54a5dfa   3 seconds ago  1.03GB
```
docker image가 정상적으로 생성되었다.

```bash
$ sudo docker run -d --name <container name> -p 80:1234 <image name>
```
위 명령어로 container를 생성하고 구동해보면 정상동작하는 것을 알 수 있다. 이제 fly.io로 올려보자.

#### fly.io

fly.io는 기존에 사용해봐서 익숙한 사이트이다. 서버 호스팅 사이트인데, $5 미만은 과금을 면제해주는 정책이라서 간단한 프로젝트를 올려두기에 좋은 곳이다. 그래서 fly.io를 사용하기 전에 사용하던 호스팅 사이트가 유료화로 변경됐을 때 fly.io로 이관했었는데 지금까지 잘 사용하고 있다. 아주 감사한 사이트이다. 그런데 이 사이트를 사용하면서 한 가지 이슈가 있었는데, 이 사이트가 docker기반으로 동작한다는 것이다. 지난 주에 docker를 아주 조금 사용해본 적이 있다는 글을 적었는데, fly.io에 배포를 하려다 보니 사용해보게 되었던 것이다. 기존에 사용하던 사이트를 수업에서 사용한다니! 반가웠다.

```bash
$ curl -L https://fly.io/install.sh | sh
```
먼저 fly.io의 CLI 프로그램을 설치해주었다.

```bash
$ flyctl auth login
$ flyctl launch --no-deploy
$ flyctl deploy
```
그리고 나서 로그인을 해주고 `flyctl launch`를 해주면 Dockerfile을 통해 app을 자동으로 build해준다! 그리고 `flyctl deploy`까지 해주면 배포완료! 아주 간단하다!

#### 간단한 머신러닝으로 학습하기 : K-Nearest Neighbor

마지막으로 간단한 머신러닝으로 물고기 종류를 판별하는 모델을 학습시켜 보았다.

K-Nearest Neighbor는 아주 간단한 지도학습 모델이다. K개의 가장 가까운 이웃(데이터)를 확인하고 가장 많은 class로 예측하는 아주 단순한 모델. 하지만 제법 강력한 모델이라고 대학원에서 배웠던 기억이 있다. 사용하는 법도 아주 간단하다. 

```python
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier

# 데이터 출처 : https://www.kaggle.com/datasets/vipullrathod/fish-market
bream_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0]
bream_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0]

smelt_length = [9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]
smelt_weight = [6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]

length = bream_length + smelt_length
weight = bream_weight + smelt_weight

plt.scatter(bream_length,bream_weight,color="#F9A8A0")
plt.scatter(smelt_length,smelt_weight,color="#CFE6CC")
plt.xlabel("length")
plt.ylabel("weight")
plt.show()
```
먼저 데이터 분포를 살펴보면 두 물고기는 확연하게 구분되는 특징을 가지는 것으로 보인다. 예측이 아주 잘 될 것 같다.

다음으로 학습을 위한 데이터를 만들었다.
```python
fish_data=[]
fish_target=[1]*len(bream_length) + [0]*len(smelt_length)

for l,w in zip(length,weight):
    fish_data.append([l,w])

print(fish_data)
print(fish_target)
```
그리고 생성된 데이터를 이용해 모델을 학습시켰다.

```python
knn = KNeighborsClassifier()
knn.fit(fish_data, fish_target)
```
그리고 학습된 모델을 통해 예측을 해보았다.

```python
pred = knn.predict([[30.1, 600.123]])
print(pred)     # [1]
```
결과가 list로 나타나는 것을 확인할 수 있다. 결과를 더 가독성 있게 확인하기 위해 아래와 같이 해주었다.

```python
CLASSES = {
    0:"빙어",
    1:"도미"
}
print(CLASSES[pred[0]])     # 도미
```
이제 학습된 모델을 파일로 저장하여 FastAPI에서도 학습된 모델을 사용할 수 있도록 해주면 된다.

```python
import pickle

with open("model.pkl", "wb") as f:
    pickle.dump(knn,f)                  # 파일로 저장

with open("model.pkl", "rb") as f:
    fish_model=pickle.load(f)           # 저장된 파일 읽어오기

fish_model.predict([[30.1, 600.123]])   # array([1])
```
파일을 읽어와서 예측하는 것이 잘 동작하는 것을 확인할 수 있다. 그대로 FastAPI에 넣어주면 요구사항 구현 완료!

```python
@app.get("/fish")
def fish(length:float, weight:float):
    """
    어종 판별기

    Args:
     - length(int): 물고기 길이(cm)
     - weight(int): 물고기 무게(g)

    Return
     - dict, 물고기의 종류를 담은 딕셔너리
    """

#    if length>=30:
#        pred="도미"
#    else:
#        pred="빙어"

    with open("./model/model.pkl", "rb") as f:
        fish_model=pickle.load(f)

    pred=fish_model.predict([[length, weight]])[0]

    CLASSES={
                0:"빙어",
                1:"농어"
            }
            
    return {
            "prediction":CLASSES[pred],
            "length":length,
            "weight":weight
            }
```
### 정리

오늘은 FastAPI가 간단한 머신러닝 결과를 반환하도록 하는 하나의 프로그램을 만드는 일련의 과정을 수행해보았다. 그 과정에서 Dockerfile도 만들어 보았는데 꽤 유용하게 쓸 수 있을 것 같다. 

예전에 패스트캠퍼스에서 인터넷 강의를 들으며 딥러닝에 대해 공부할 때, 내가 조합한 MNIST 판별 모델을 웹사이트에서 어떻게 다른 사람들에게 보여줄 수 있을지 생각해본 적이 있었는데 오늘 그 답을 들은 것 같은 기분이다. 해당 모델을 파일로 저장하는 방식으로 제공할 수 있다. 다음에 한 번 시도해봐야겠다.
