## airflow에 대해 좀 더 깊게 알아보기

오늘은 DevOps라는 키워드로 강의가 시작되었다.

DevOps는 Develop와 Operation 즉, 개발과 운영을 합친 단어이다.

전통적으로 개발과 운영은 서로 분리되어 있었다고 한다. 개발자가 대규모로 개발을 하고 그것을 문서화하여 운영자에게 업무를 인계해주는 구조인 것이다. 이러한 구조는 몇 가지 문제를 가지고 있었다. 먼저, 개발자와 운영자는 서로에 대한 이해가 부족했다. 운영자의 입장에서 개발이 어떻게 된 것인지 알기 어렵고, 추후 오류가 발생하거나 추가적인 요구사항이 발생할 경우 처리하기 어려웠다. 또한, 개발자가 스파게티 코드로 개발을 해놓고 철수한 경우 운영 입장에서는 개선하기 난해하다. 

이러한 관점에서 DevOps라는 개념이 나타났다. 트위터의 사례에 따르면, 개발을 6개월 동안 하고 3개월 동안은 시스템 운영을 맡는다고 한다. 그렇게 운영이 끝나면 다시 개발로 돌아가는 식으로 순환하는 것이다. 이런 식으로 하면 개발과 운영 모두 원활해질 수 있다.

마지막으로 개발을 잘하는 사람이 되기 위해서는 운영을 잘 할 수 있는 사람이 되어야한다고 강조하셨다.


#### airflow - BashOperater, trigger_rule
전체적인 코드는 어제와 비슷하다
```bash
from datetime import datetime, timedelta
from textwrap import dedent

from airflow import DAG

from airflow.operators.bash import BashOperator
from airflow.operators.empty import EmptyOperator

with DAG(
    'simple_bash',
    default_args={
        'depends_on_past': False,
        'retries': 1,                                     # 실패시 몇 번 다시 시도하는지
        'retry_delay': timedelta(seconds=3)               # 재시도 간격
    },
    description='hello world DAG',
#    schedule_interval=timedelta(days=1),
    schdule = "10 4  * * *"
    start_date=datetime(2024, 7, 10),
    catchup=True,
    tags=['simple', 'bash', 'etl', 'shop'],
) as dag:

    task_date = BashOperator(
        task_id='print.date',
        bash_command="""
            echo "data => `date`"									# Thu Jul 18 10:19:02 KST 2024
            echo "ds => \{\{ds\}\}"									# 2024-07-13
            echo "ds_nodash => \{\{ds_nodash\}\}"							# 20240713
            echo "logical_date => \{\{logical_date\}\}"							# 2024-07-13 00:00:00+00:00
            echo "logical_date => \{\{logical_date.strftime("%Y-%m-%d %H:%M:%S")\}\}"			# 2024-07-13 00:00:00
            echo "execution_date => \{\{execution_date\}\}"						# 2024-07-13 00:00:00+00:00, logical_date와 동일. deprecated되었지만 현업에 많이 사용되어 있음.
            echo "execution_date => \{\{execution_date.strftime('%Y-%m-%d %H:%M:%S')\}\}"		# 2024-07-13 00:00:00
            echo "next_execution_date => \{\{next_execution_date.strftime('%Y-%m-%d %H:%M:%S')\}\}"	# 2024-07-14 00:00:00
            echo "prev_execution_date => \{\{prev_execution_date.strftime('%Y-%m-%d %H:%M:%S')\}\}"	# 2024-07-12 00:00:00
            echo "ts => \{\{ts\}\}"									# 2024-07-13T00:00:00+00:00
        """
    )

    task_end = EmptyOperator(task_id='end', trigger_rule='all_done')
    task_start = EmptyOperator(task_id='start')

    task_start >> task_date >> task_end
```
먼저 dag를 선언하는 부분에서 `depends_on_past`를 보자. 직역하면 "과거에 의존한다"인데, 느낌적으로 알 수 있지만 해당 부분이 `True`로 되어 있으면 과거의 실행이 성공한 경우에만 다음 날짜의 파이프라인이 구동된다. 과거의 실행과 무관하게 모든 파이프라인을 구동하려면 False로 하면 된다. 

![화면 캡처 2024-07-18 141748](https://github.com/user-attachments/assets/a52f3684-b4db-4e60-a655-ad5713222bbf)

그리고 날짜를 출력하는 여러 가지 명령어를 확인해보았다. 눈 여겨 볼 부분은 data의 경우 bash 명령어라서 \`\` 안에 적어주었지만, 나머지는 airflow에서 제공하는 기능이므로 {{}} 내에 적었다는 것이다. {{}} 내에 적는 문법을 `jinja template`이라고 하는데, airflow 뿐만 아니라 django 등 많은 python 라이브러리에서 사용된다. 그리고 각 날짜 형식이나 어느 날짜를 나타내는지도 눈 여겨볼 부분이다. 당연히 요구에 맞게 데이터 형식을 formatting하는 것도 가능하다. [공식문서](https://airflow.apache.org/docs/apache-airflow/stable/templates-ref.html#templates-reference) 참조.

`BashOperator`는 간단하게 Bash로 명령어를 수행하는 부분이다. argument를 살펴보면 `bash_command`를 찾아볼 수 있는데, 해당 부분에 지정한 command를 수행하는 것이다. 이 때 bash로 명령어를 수행하므로 당연히 bash명령어로 적어주어야 한다. 이 때, jinja template부분은 bash가 아닌  airflow가 값을 채우게 된다.

또한, 앞의 작업이 성공일 때의 작업흐름과 실패일 때의 작업흐름을 분기하고 싶을 수 있다. 이 때 사용할 수 있는 것이 `trigger_rule`이다. [공식문서](https://airflow.apache.org/docs/apache-airflow/1.10.3/concepts.html#trigger-rules)에 보면 여러 가지가 있다. 기본적인 trigger_rule은 `all_success`이다. 이 규칙은 앞의 프로세스가 모두 성공해야 해당 프로세스를 수행하게 된다. 다른 프로세스로는 `all_done`가 있는데, 이 규칙은 앞의 프로세스가 성공인지 실패인지와 무관하게 실행되면 해당 프로세스를 실행하게 된다. 앞의 프로세스가 하나라도 실패할 경우에만 실행되는 `one_failed`도 있다. 그 외 여러가지 규칙은 공식문서 참조.

end는 모든 분기가 의도대로 수행되었다면 반드시 success가 되는 component로, 확인용으로 사용된다.

#### cron
위 파이프라인에서 또 한 가지 눈여겨 볼 부분 중 하나는 schedule부분이다. shedule_interval은 deprecated되었기 때문에 schedule을 사용해야 하는데, 해당 값으로 `cron`을 지정할 수 있다. cron은 Unix계열에서 사용되는 job scheduler이다. 아래와 같이 5개의 숫자로 구성되는데 각각 분, 시, 일, 월, 요일을 나타낸다.

```bash
$ crontab -e							# 최초 cron을 설정
no crontab for user - using an empty one

Select an editor.  To change later, run 'select-editor'.	# 최초 에디터를 선택. 추후 변경하고 싶다면 select-editor
  1. /bin/nano        
  2. /usr/bin/vim.basic
  3. /usr/bin/vim.tiny
  4. /bin/ed

10 4 * * * <command>						# 분 시 일 월 요일, 예시는 매일 4시 10분 마다 실행됨.
```

#### 멱등성
여기서 다시 멱등성에 대한 이야기를 조금 해볼 수 있다.

airflow pipeline에서 수행한 일을 모두 clear하고 지난 날짜의 pipeline을 다시 수행할 수 있는데, 몇 번을 다시 수행시키더라도 항상 같은 결과를 산출해야 한다는 것이다. 

추가적으로 오늘의 pipeline을 수행하면 어제 날짜의 데이터가 축적된다. 오늘 날짜의 데이터가 축적되도록 설정할 수 있지만, 관례적으로 그렇다고 한다.

### 정리
오늘은 정말 모르는 것에 대해 많이 배웠다. airflow가 처음이니까 아무래도 그렇다. 그런데 생각보다 사용하기 편리하다는 생각이 쓰면서 계속 든다. 그만큼 잘 만들었다는 것일 것이다. (물론 UI페이지를 많이 사용해서 그럴지도)

나도 이런 편리한 무언가를 만들어낼 수 있을까? 그렇게 되면 좋을 것 같다. 
