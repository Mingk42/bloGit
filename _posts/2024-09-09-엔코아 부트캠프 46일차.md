## KNeighborsRegression, LinearRegression

#### KNeighborsRegression

지난 주의 분류에 이어서 오늘은 회귀모형에 대해 학습하였다. 먼저 KNeighborsRegression으로 회귀모형에 대한 학습을 시작하였다. KNeighborsRegression은 지난 주에 분류모형에 사용했던 KNN과 비슷한 방식으로 동작하는데 근접한 이웃들의 평균울 회귀모형의 추정값으로 반환하는 방식이라고 한다. 그리고 이러한 모형의 한계는 뚜렷하다.

```
>>> knr=KNeighborsRegressor()
>>> knr.n_neighbors=3
>>> knr.fit(train_x, train_y)

>>> for i in [i for i in range(40, 51)]:
>>>     print(f"length={i} ==> pred_weight={knr.predict([[i]])}")
length=40 ==> pred_weight=[921.66666667]
length=41 ==> pred_weight=[921.66666667]
length=42 ==> pred_weight=[1066.66666667]
length=43 ==> pred_weight=[1033.33333333]
length=44 ==> pred_weight=[1033.33333333]
length=45 ==> pred_weight=[1033.33333333]
length=46 ==> pred_weight=[1033.33333333]
length=47 ==> pred_weight=[1033.33333333]
length=48 ==> pred_weight=[1033.33333333]
length=49 ==> pred_weight=[1033.33333333]
length=50 ==> pred_weight=[1033.33333333]
```
결과를 보면 알 수 있는데, 독립변수의 값이 어떤 지점 이상으로 올라가면 추정값이 모두 일관되게 나타난다. 가까운 이웃이 모두 동일해질 것이기 때문이다. (아래 그림을 보면 이해가 쉽다.)

###### length=40
<img src="https://github.com/user-attachments/assets/2e9c56a3-0de7-4c4d-a54e-748a82cc782b" width="30%" />

###### length=42
<img src="https://github.com/user-attachments/assets/c905e2d2-872b-4ebc-831f-31b73c37b16f" width="30%" />

###### length=43
<img src="https://github.com/user-attachments/assets/af5513a1-0886-4a4d-8cb5-317291a5ea68" width="30%" />

###### length=45
<img src="https://github.com/user-attachments/assets/9f331b89-0ea6-49a4-acd5-c76ab19c9f82" width="30%" />

###### length=50
<img src="https://github.com/user-attachments/assets/b97c16c6-6ab4-4919-aaee-95687924b9ff" width="30%" />

정리하자면, KNeighborsRegression은 어떠한 범위 내에서는 추정을 곧잘 하지만, 그 범위를 벗어나면 추정을 제대로 하지 못한다.

#### LinearRegression

여기서 우리가 사용할 수 있는 것이 LinearRegression이다. 회귀분석은 통계학에서도 중요하게 다뤄지는 분석방법 중 하나인데, 아주 간단하게 말해서 데이터를 가장 잘 설명하는 하나의 직선의 방정식을 찾는 것이다. 사용하는 법도 아주 간단한데, 모형을 불러오고 독립변수와 종속변수를 fit() 함수에 넣어주면 끝이다.

```python
from sklearn.linear_model import LinearRegression

lr=LinearRegression()
lr.fit(fish_length.reshape(-1,1), fish_weight)          # 한 가지 중요한 것은 독립변수가 2차원 배열이어야 한다.

lr.predict([[50]])        # array([1241.83860323])
```
위 KNR 모델에서는 길이가 43을 넘는 경우 모두 1033.33..으로 예측했지만 선형회귀 모형은 길이가 50인 경우에도 알맞은 추정값을 반환한다.

이를 그래프로 나타내보면 아래와 같다.

<img src="https://github.com/user-attachments/assets/252a016a-d349-4684-935d-09ed0691b98b" width="30%" />

그래프를 보면 2가지 마음에 걸리는 부분이 있다.
1. 길이의 값이 작은 경우에 대해서 무게의 오차가 커보인다.
2. 길이의 값에 따라 무게의 추정값은 작아지다가 음수가 되어버리기도 한다.

이를 해결하기 위해 회귀모형을 2차식으로 만들어 볼 수 있다.

```python
lr = LinearRegression()

train_poly = np.column_stack((train_x**2,train_x))
lr.fit(train_poly, train_y)
lr.predict([[50**2,50]])
```
그래프로 나타내면 아래와 같다.

<img src="https://github.com/user-attachments/assets/8605784b-79e4-46d3-b2cc-363133f2cf51" width="30%" />

다만, 이 모형도 문제가 있는 것은 ① 길이에 따라 무게가 음수가 되는 부분이 아직 조금 남아있다는 것 ② 그리고 2차 모형의 특성상 길이에 따라 무게의 추정값이 기하급수적으로 크게 추정된다는 것이다.

#### LinearRegression - KNeighborClassifier 연결하기

마지막으로 LinearRegression를 다시 FastAPI로 만들어서 지난 주에 만들었던 KNeighborClassifier FastAPI와 연결하였다. 앞단에 LinearRegression를 두고 길이만 입력하여 보내면 무게를 추정하여 길이와 무게값을 KNeighborClassifier로 다시 넘겨준다. 그러면 길이 입력만으로 물고기가 도미인지 빙어인지 예측할 수 있게 된다는 아이디어이다.

먼저 빙어와 도미에 대해 회귀 모형을 다시 생성해야 했다. (위에서 실습한 데이터는 또 다른 물고기이다.) 
###### 1차 회귀모형 (score : 0.922)
<img src="https://github.com/user-attachments/assets/882b3fa4-92d0-4aee-94a4-a0236572cbc2" width="30%" />

###### 2차 회귀모형 (score : 0.967)
<img src="https://github.com/user-attachments/assets/1dd878df-22c8-4f75-bcc2-a3413db19d3e" width="30%" />

###### 3차 회귀모형 (score : 0.969)
<img src="https://github.com/user-attachments/assets/88a21986-f047-4000-a5bf-602f269afe6f" width="30%" />

그래프를 보면 2차 회귀모형이 가장 적합한 모형으로 보인다. 이는 score를 봐도 알 수 있는데 1차 모형과 2차 모형은 2차 모형이 확실히 우세한 반면, 2차 모형과 3차 모형은 미미한 차이이다. 2차 모형 계산량과 3차 모형 계산량을 비교할 때 약간의 오차를 감수하더라도 2차 모형을 선택하는 것이 성능에 도움이 된다. 

그 후는 KNN 때와 동일하게 pkl파일을 만들고 FastAPI로 만들면 된다.

마지막으로 두 FastAPI를 모두 호출할 수 있는 함수를 만들었다.
```python
def pred():
    l = input("🐳 물고기의 길이를 입력해주세요 : ")

    resp = reqs.get(f"http://localhost:8001/fish?length={l}").text
    w=eval(resp)["prediction"]

    resp = reqs.get(f"http://localhost:8002/fish_std?length={l}&weight={w}&nneighbor=5").text
    pred=eval(resp)["prediction"]

    print(f"\n🐳 입력한 물고기의 길이는 {l}입니다.")
    if float(w)<0:
        print(f"🐳 물고기의 무게는 너무 작아 예측이 어렵습니다.")
    else:
        print(f"🐳 물고기의 무게는 {w}로 예측됩니다.")
    print(f"🐳 물고기의 종류는 {pred}로 예측됩니다.\n")
```
이를 구현하기 위해 2번의 request를 사용하였다. 한 가지 문제가 있었는데, 길이가 작아지는 경우 음수로 무게를 추정한다는 것이다. 그래서 무게가 음수로 추정되는 경우 예측하지 못한다는 문구로 대체하였다.

### 정리

기계학습에 대해 조금은 배웠었는데 KNeighborsRegression가 있다는 것을 처음 알았다. 중요도가 떨어져서 가르쳐주지 않았다고 생각했고, 각자 상황에 맞는 방법이 있다고 생각했다. KNN은 분류에 적합한 알고리즘이고 값의 추정에 대해서는 당연히 회귀모형이 더 좋은 모델이라고 생각했다. 그런데 마지막에 길이에 따라 무게가 음수로 추정되는 문제는 KNR을 사용하면 해결될 수 있는 문제이다. 그렇게 생각해보면 언제나 좋은 모델은 역시 존재하지 않는 것이고, 상황에 맞게 도구를 선택하는 것이 중요한 것 같다. ① 범위 내에서는 KNR-범위 밖에서는 LR 또는 ② 길이가 특정 범위 이하에 대해 KNR-그 이상에서는 LR과 같이..
