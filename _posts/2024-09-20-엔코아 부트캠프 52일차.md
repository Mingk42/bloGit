## worker scheduling

오늘의 할 일은 아래 요구사항을 구현하는 것이었다.

- WORKER 는 주기적으로 image_processing 테이블을 읽어서 가장 오래된 요청 하나씩을 처리한다.
- DNN 모델이 없는 상황에서는 일단 0~9 중에서 임의의 값을 image_processing 테이블에 업데이트 한다.
- WORKER 는 pip install 하면 ml-worker 라는 cmd 로 동작하도록 하고 도커 안에서 crontab 설정으로 3분 마다 동작한다

여기서 1번과 3번은 주기적 실행이라는 부분에서 비슷한 부분이 있다. 이를 구현하기 위해서 아래와 같이 cronjob을 만들고 이를 Docker build할 때 등록하도록 구현하였다. 

##### ml-work-cronjob (scheleduling할 파일)
```
*/3 * * * * /usr/local/bin/ml-worker >> /var/log/worker.log 2>&1
```

##### pyproject.toml (cronjob에서 실행하는 ml-worker를 정의)
```bash
...
[project.scripts]
ml-worker = 'mnist.worker:run'
...
```

##### Dockerfile
```bash
FROM python:3.11

WORKDIR /code

RUN apt update
RUN apt install -y cron
COPY ml-work-cronjob /etc/cron.d/ml-work-cronjob        ### cronjob으로 등록하고
RUN crontab /etc/cron.d/ml-work-cronjob                 ### cronjob을 구동한다

COPY src/mnist/main.py /code/
COPY run.sh /code/run.sh

RUN pip install --no-cache-dir --upgrade git+https://github.com/dMario24/mnist.git@0.3.6

CMD ["sh", "run.sh"]
```

##### run.sh
```bash
#!/bin/bashservice cron start;
uvicorn main:app --host 0.0.0.0 --port 8080 --reload;
```

너무 많은 코드가 갑자기 쏟아져서 어질어질한 것 같기도 하다. 전체적인 흐름만 보면 되는데 cronjob을 수행하기 위한 작업들이라고 보면 대충 맞다.

여기까지 하면 3번째 요구사항은 만족했다. `ml-work-cronjob` 파일에서 3분마다 수행하도록 지정하였기 때문이다. 그리고 1번 요구사항도 주기적으로 동작한다는 부분은 만족되었다. 이제 테이블을 읽고 가장 오래된 요청부터 처리하도록 구현하면 된다.

```python
import random
import os

from tz_kst import now
from mnist import db
from mnist.line_notify import send

def run():
    """image_processing 테이블을 읽어서 가장 오래된 요청 하나씩을 처리"""
    
    # STEP 1
    # image_processing 테이블의 prediction_result IS NULL 인 ROW 1 개 조회 - num 갖여오기
    data= db.get_train_data()

    if data==None:
        print(f"[{now()}] 예측할 데이터가 없습니다.")
        return None

    # STEP 2
    # RANDOM 으로 0 ~ 9 중 하나 값을 prediction_result 컬럼에 업데이트
    # 동시에 prediction_model, prediction_time 도 업데이트
    pred = random.randint(0,9)
    prediction_model="randint"
    prediction_time=now()

    sql = f"""
    UPDATE image_processing
    SET prediction_model='{prediction_model}', prediction_result='{pred}', prediction_time='{prediction_time}'
    WHERE num={data}
    """
    row_cnt= db.dml(sql, )


    # STEP 3
    # LINE 으로 처리 결과 전송
    send(f"{data}번째 이미지의 예측결과는 {pred}입니다.")

    print(f"[{prediction_time}] {data}번째 이미지의 예측결과는 {pred}입니다.")

    return {
        "prediction_time":prediction_time,
        "train_data_nth":data,
        "pred":pred
    }
```
여기까지 하면 2번째 요구사항도 만족한다. step2에서 randint로 예측값을 제공했기 때문이다. 또한, 1번째 요구사항도 만족한다.

요구사항 구현 완료! 오늘 작업 끝!

인 줄 알았다. 끝이었어야 했다.

#### docker env

위 구현사항은 최종적으로 docker로 build되어 동작한다. 그리고 정상적으로 동작하기 위해서는 DB_IP와 LINE_TOKEN이 환경변수로 제공되어야 한다. LINE_TOKEN의 경우 코드 상에 하드코딩하는 것은 보안 위험이 있고, DB_IP는 localhost이긴 하지만 실제 local과 docker 내부에서 다른 값을 가지기 때문에 동적으로 동작하도록 환경변수를 받도록 하였다. 그렇다면 우리는 build된 docker image를 run할 때 `-e, --env` 옵션을 이용하여 필요한 환경변수를 넘겨줄 수 있을 것이다.

```bash
$ docker run -d -p 8080:8080 -e DB_IP=172.17.0.2 -e LINE_TOKEN=1234 --name app <docker image>
```
이렇게 실행시키면 직접 해야할 일은 없다. 예측할 데이터가 있다면 scheduling에 의해 자동으로 가져가고 예측결과를 line으로 전송해줄 것이다.

그런데 어떻게 된건지 계속 오류가 발생했다. 
```bash
...
ConnectionRefusedError: [Errno 111] Connection refused
...
```
이 오류는 DB IP가 docker 내부 ip로 되어있지 않아 발생하는 오류였다. 하지만, 분명히 docker를 run하면서 환경변수로 ip를 넘겨주었다. 오류의 발생 여지가 없었다. 하지만 오류가 발생한다. 계속...

이 부분을 해결하는데 6시간 정도는 쓴 것 같다.

몇 번을 다시 시도해도 오류가 발생했다. 처음에는 환경변수가 넘어가지 않는 문제가 아닐까 생각도 했었다. 그래서 해당 문제로 구글링을 해봤지만 좋은 답을 찾기 어려웠다.

그런데 문득, 이게 cron의 문제일 수도 있다는 생각이 들었다. 그래서 cron에서 환경변수를 못 읽는 문제에 대해 구글링을 했더니 같은 문제를 가진 사람이 있었고 알맞은 답을 찾을 수 있었다.

해결방법은 run.sh의 동작에 `env >> /etc/environment;`를 추가하는 것이었다!

cron의 경우 환경변수를 잘 읽지 못하는 문제가 있는데, `/etc/environment`로 옮겨주면 해당 환경변수를 읽을 수 있다고 한다.

이렇게 하고 나니 모든 것이 정상적으로 동작했다! 진짜 끝

### 정리

cron이 환경변수를 읽지 못하는 문제는 예상치 못한 문제라 너무 괴로웠다. 하지만 그것을 해결하고 나니 그 쾌감도 두배였던 것 같다. 굿굿 