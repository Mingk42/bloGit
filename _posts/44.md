## FastAPI 부하테스트 이어서

#### stress test on AWS EC2

오늘도 어제에 이어서 부하테스트를 진행했다. 다만 어제와 다른 것은 AWS EC2에서 부하테스트를 진행했다는 것이다. 

[구성도]

기존에 로컬에서 부하테스트를 진행했을 때는 여러가지 프로그램이 함께 실행되고 있었기 때문에 순수 성능을 보이지 못했을 가능성이 있는데, 오늘의 테스트는 각 부분을 전용 EC2로 구성하였기 때문에 방해요인이 없이 순수한 성능을 확인해볼 수 있었다. 

이를 위해 먼저 각 EC2를 세팅해주었다.

#### EC2_nginder

먼저 ngrinder를 설치해보았다. 사실 ngrinder는 특별하게 세팅을 할 건 없었다. controller를 다운로드 받았고, agent는 로컬에 있던 파일을 scp로 옮겨주었다. 그리고 jdk-11을 설치해주었다. 

준비 완료!

#### ml server

ml server도 어렵지 않았다. 기존에 로컬에서 만든 이미지를 docker hub에 올려두었는데 받아와서 실행해주면 되는 것이었다. 다만 로컬에서 할 때와는 다르게 포트를 지정해주어야 한다. 서로 다른 인스턴스(~다른 PC)에서 동작하고 있으므로 `--link`옵션을 사용할 수 없기 때문이다.

#### EC2_Load Balance

Load balance를 위해 docker image로 nginx를 build하였다. nginx에서 proxy를 적용하기 위해 default.conf파일을 포함하여 build하였는데 이 부분이 중요한 부분이었던 것 같다!

###### default.conf
```bash
upstream ml_servers {
        server <ml-1 server private ip>:8080;
        server <ml-2 server private ip>:8080;
        server <ml-3 server private ip>:8080;
}

server {
        listen 80;

        location /
        {
                proxy_pass http://ml_servers;
        }
}
```

위에서 언급했듯이 `--link`옵션을 사용할 수 없으니 아이피를 명시해주어야 한다. 이 때, public ip가 아니라 private ip를 적어주어야 한다는 것이다!

ml server를 run한 상태에서 브라우저로 접속할 때는 public ip로 접속이 가능했다. 그래서 처음에는 당연히 public ip를 명시하고 build하였는데 접속이 정상적으로 되지 않았다. 그리고 문제 원인이 private ip라는 것을 알게 되었을 때 뭔가 의문스러웠다. 그리고 그 이유를 나중에 강사님이 설명해 주셨다.

어쨋든 build하고 실행해보면... Load balance 구축 완료!

#### 부하 테스트 실행

이제 부하테스트를 진행해 볼 시간!



### 정리
