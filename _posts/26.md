## stress test Ⅱ & fastapu

지난 주에 하던 부하테스트를 이어서 하는 시간을 가졌다. 그리고 fastapi를 이용하여 api를 만들어 보는 시간을 가졌다.

#### stress test Ⅱ

지난 주에 이어서 부하테스트를 계속하였다. 

![image](https://github.com/user-attachments/assets/0c5c36fe-b8b3-4801-b3f0-07bd28fa878f)
테스트 환경은 위의 테스트에서는 nginx 뒷단에 서버가 2개 연결되어 있었고, 아래 테스트에서는 1개가 연결되어 있었다. 그리고 모든 서버는 `cpulimit -p <pid> -l 5 -c 1`로 cpu사용량을 제한하였다. 그리고 가상유저 1000명이 동시접속하는 것을 가정하였는데 10개의 프로세스에서 각 100개의 스레드가 구동되는 환경이다. 동시접속자는 5초 마다 조금씩 증가시키면서(ramp up) 10분 정도 지속되었다.

![결과사진1](https://private-user-images.githubusercontent.com/174768977/356927183-332e17e9-f5af-4e49-908b-0f59267be494.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjM1MDc5MjYsIm5iZiI6MTcyMzUwNzYyNiwicGF0aCI6Ii8xNzQ3Njg5NzcvMzU2OTI3MTgzLTMzMmUxN2U5LWY1YWYtNGU0OS05MDhiLTBmNTkyNjdiZTQ5NC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwODEzJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDgxM1QwMDA3MDZaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0xZDgwZWZmMzc3NjZhNTQ3OTYxZmJkZjZjNGZkZjNkNWZmMzU3ODE2MmQyZDgyNWRlMTk3OTU0M2I2NjQwMWRjJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.bTjUh7k1sXZCL2FBth0-AnCkPUMon4Zibyeh38peS3Q)

결과를 보면 서버가 2개가 되면서 전체적으로 성능이 개선된 것으로 보이지만 어느 순간 동일하게 오류가 증가 추세를 보인다. log를 확인해보니 1번 서버에서 BrokenPipeError를 나타냈다. 이는 서버가 1개 있을 때와 2개 있을 때 동일하게 나타난 오류이다.

![결과사진2](https://private-user-images.githubusercontent.com/174768977/356939988-5d5dc034-d04e-427b-ac57-30292a39c4fe.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjM1MTI2MjgsIm5iZiI6MTcyMzUxMjMyOCwicGF0aCI6Ii8xNzQ3Njg5NzcvMzU2OTM5OTg4LTVkNWRjMDM0LWQwNGUtNDI3Yi1hYzU3LTMwMjkyYTM5YzRmZS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwODEzJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDgxM1QwMTI1MjhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03YTI5ZjBhMDA3M2VlNjY5Yzc1YWI4M2NiZjI3NWIyMDk2NGU4YWYzODdiY2Y3YTA4NWVkYjQyYmNhNjM3ZDNjJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.CY4pLjsAmdxr4ziynffrVa66haIZL8Icp4kaDMLpvgY)

이번에는 가상유저를 99명까지만 수용해보았다(3개 프로세스 33개 스레드). 앞서 1000명의 가상유저로 실험을 할 때는 중간에 서버에 오류가 발생하여 테스트를 끝까지 진행하지 못했는데, 100명의 가상유저 테스트는 성공적으로 마무리되었다. 그리고 앞선 실험보다 성능의 개선이 더 명확하게 보인다. TPS가 꺾이는 시점도 확연하게 후반에 위치한 것이 보이고, MTT를 보아도 서버가 2개일 때 훨씬 안정된 모습을 보인다.

### 정리
