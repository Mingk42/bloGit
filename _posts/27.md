## spark clustering

오늘은 spark clustering에 대해 학습해보았다.

#### spark - master & worker 

며칠 전에 spark를 처음 학습할 때는 spark docs에 있는 예제를 그대로 하나의 파일로 작성하여 `spark-submit`파일을 이용하여 파일을 실행시켰다. 이 방식은 간편하지만, 분산처리라는 관점에서 과연 큰 도움이 될까?라는 생각을 해볼 수 있다. 그리고 이를 위한 방법이 master-worker를 사용하는 것이다.

먼저 master를 실행시킨다.

```bash
$ $SPARK_HOME/sbin/start-master.sh
```

실행이 되고 나면 log파일이 저장된 경로가 나타난다. 해당 파일을 열어보면 `Bound MasterWebUI to 0.0.0.0, and started at http://10.255.255.254:8080`이라는 문구를 마주칠 수 있다. localhost:8080으로 접속해보면 아래와 같은 화면을 마주칠 수 있다.
![image](https://github.com/user-attachments/assets/fd5e3a20-8707-4ae0-8752-766d7230ac21)
여러가지 정보가 나타나는데 `Spark Master at spark://STU3-1151.:7077`라고 쓰여진 제목이 보인다. 이 정보를 이용해서 해당 master로 worker를 연결해보자.

```bash
$ $SPARK_HOME/sbin/start-worker.sh spark://STU3-1151.:7077
```
역시 log가 저장되는 경로가 나타나는데 해당 log를 열어보면 worker는 8081포트에서 WebUI가 제공되고 있음을 확인할 수 있다.
![image](https://github.com/user-attachments/assets/c16689b7-9a67-4b48-bcfa-e3394a6d31cc)

그리고 master의 WebUI로 돌아가보면 아래와 같이 변한 모습이 보인다.
![image](https://github.com/user-attachments/assets/fd5e3a20-8707-4ae0-8752-766d7230ac21)


### 정리
