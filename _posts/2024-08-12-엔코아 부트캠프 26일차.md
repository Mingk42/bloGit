## stress test Ⅱ & fastapu

지난 주에 하던 부하테스트를 이어서 하는 시간을 가졌다. 그리고 fastapi를 이용하여 api를 만들어 보는 시간을 가졌다.

#### stress test Ⅱ

지난 주에 이어서 부하테스트를 계속하였다. 

![image](https://github.com/user-attachments/assets/0c5c36fe-b8b3-4801-b3f0-07bd28fa878f)
테스트 환경은 위의 테스트에서는 nginx 뒷단에 서버가 2개 연결되어 있었고, 아래 테스트에서는 1개가 연결되어 있었다. 그리고 모든 서버는 `cpulimit -p <pid> -l 5 -c 1`로 cpu사용량을 제한하였다. 그리고 가상유저 1000명이 동시접속하는 것을 가정하였는데 10개의 프로세스에서 각 100개의 스레드가 구동되는 환경이다. 동시접속자는 5초 마다 조금씩 증가시키면서(ramp up) 10분 정도 지속되었다.

![결과사진1](https://private-user-images.githubusercontent.com/174768977/356927183-332e17e9-f5af-4e49-908b-0f59267be494.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjM1MDc5MjYsIm5iZiI6MTcyMzUwNzYyNiwicGF0aCI6Ii8xNzQ3Njg5NzcvMzU2OTI3MTgzLTMzMmUxN2U5LWY1YWYtNGU0OS05MDhiLTBmNTkyNjdiZTQ5NC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwODEzJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDgxM1QwMDA3MDZaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0xZDgwZWZmMzc3NjZhNTQ3OTYxZmJkZjZjNGZkZjNkNWZmMzU3ODE2MmQyZDgyNWRlMTk3OTU0M2I2NjQwMWRjJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.bTjUh7k1sXZCL2FBth0-AnCkPUMon4Zibyeh38peS3Q)

결과를 보면 서버가 2개가 되면서 전체적으로 성능이 개선된 것으로 보이지만 어느 순간 동일하게 오류가 증가 추세를 보인다. log를 확인해보니 1번 서버에서 BrokenPipeError를 나타냈다. 이는 서버가 1개 있을 때와 2개 있을 때 동일하게 나타난 오류이다.

![결과사진2](https://private-user-images.githubusercontent.com/174768977/356939988-5d5dc034-d04e-427b-ac57-30292a39c4fe.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjM1MTI2MjgsIm5iZiI6MTcyMzUxMjMyOCwicGF0aCI6Ii8xNzQ3Njg5NzcvMzU2OTM5OTg4LTVkNWRjMDM0LWQwNGUtNDI3Yi1hYzU3LTMwMjkyYTM5YzRmZS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwODEzJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDgxM1QwMTI1MjhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03YTI5ZjBhMDA3M2VlNjY5Yzc1YWI4M2NiZjI3NWIyMDk2NGU4YWYzODdiY2Y3YTA4NWVkYjQyYmNhNjM3ZDNjJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.CY4pLjsAmdxr4ziynffrVa66haIZL8Icp4kaDMLpvgY)

이번에는 가상유저를 99명까지만 수용해보았다(3개 프로세스 33개 스레드). 앞서 1000명의 가상유저로 실험을 할 때는 중간에 서버에 오류가 발생하여 테스트를 끝까지 진행하지 못했는데, 99명의 가상유저 테스트는 성공적으로 마무리되었다. 그리고 앞선 실험보다 성능의 개선이 더 명확하게 보인다. TPS가 꺾이는 시점도 확연하게 후반에 위치한 것이 보이고, MTT를 보아도 서버가 2개일 때 훨씬 안정된 모습을 보인다.

#### fastapi

fastapi에 대해서 배워보는 시간을 가졌다. 전에 몇 번 들어본 기억은 있는데 정확히 어떤 것인지는 알지 못했다. [fastapi](https://fastapi.tiangolo.com/)는 api framework라고 한다. 

백문이 불허일견. 직접 사용해보자.

```bash
$ pip install "fastapi[standard]"
``` 
역시 pip로 설치할 수 있다.

##### main.py
```python
from typing import Union

from fastapi import FastAPI

app = FastAPI()


@app.get("/")
def read_root():
    return {"Hello": "World"}


@app.get("/items/{item_id}")
def read_item(item_id: int, q: Union[str, None] = None):
    return {"item_id": item_id, "q": q}
```

docs에 주어진 샘플코드이다. 그리고 `fastapi dev main.py`해주면 실행가능하다.

```bash
$ fastapi dev main.py
INFO     Using path src/ffapi/main.py
INFO     Searching for package file structure from directories with __init__.py files

 ╭─ Python package file structure ─╮
 │                                 │
 │  📁 ffapi                       │
 │  ├── 🐍 __init__.py             │
 │  └── 🐍 main.py                 │
 │                                 │
 ╰─────────────────────────────────╯

INFO     Importing module ffapi.main
INFO     Found importable FastAPI app

 ╭─── Importable FastAPI app ───╮
 │                              │
 │  from ffapi.main import app  │
 │                              │
 ╰──────────────────────────────╯

INFO     Using import string ffapi.main:app

 ╭────────── FastAPI CLI - Development mode ───────────╮
 │                                                     │
 │  Serving at: http://127.0.0.1:8000                  │
 │                                                     │
 │  API docs: http://127.0.0.1:8000/docs               │
 │                                                     │
 │  Running in development mode, for production use:   │
 │                                                     │
 │  fastapi run                                        │
 │                                                     │
 ╰─────────────────────────────────────────────────────╯

INFO:     Will watch for changes in these directories: ['/home/root2/code/ffapi']
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
INFO:     Started reloader process [12442] using WatchFiles
INFO:     Started server process [12537]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
```
잘 보면 127.0.0.1:8000으로 접속가능하다고 한다. 그리고 127.0.0.1:8000/docs로 접속하면 깔끔한 UI로 내용을 확인해볼 수 있다. (여기에 나타나지 않지만 /redoc 도 있다.)

다시 한 가지 실험을 해보려고 한다. read_parquet를 함수 내의 지역변수로 설정하는 것과 전역변수로 설정하는 것 사이의 속도 차이이다.

결과는 아래와 같다.
![결과사진3](https://private-user-images.githubusercontent.com/174768977/356976146-19b97851-20d0-46ef-a26a-b514bf1c82a3.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjM1MTQ2NjIsIm5iZiI6MTcyMzUxNDM2MiwicGF0aCI6Ii8xNzQ3Njg5NzcvMzU2OTc2MTQ2LTE5Yjk3ODUxLTIwZDAtNDZlZi1hMjZhLWI1MTRiZjFjODJhMy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwODEzJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDgxM1QwMTU5MjJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT00YTZhYzAwNjEyZDhmMjEzODc3MDY5ZDU4ZDhiODdjMDI0ZWFhOGZmNzc0OWEzNzMzMWFkZTk2YTNmY2ZiNTg5JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.9Wwr7QC4_Xiz2Jz9orEOFrzNRt0TKb_CZoR__ca6D6A)
전체적으로 성능이 극단적인 차이를 나타내지는 않는 모습이다. 다만, 지역변수에서는 순간적으로 MTT가 치솟는 부분이 존재하는 반면 전역변수에서는 안정적인 모습을 보여준다. 단, 지금은 큰 차이가 아니지만 나중에는 큰 차이가 될 수 있음을 코드레벨에서 대충 생각해볼 수는 있다. 지역변수로 데이터를 불러오게 되면 매번 다시 데이터를 다시 read하는 반면에 전역변수로 설정하게 되면 처음에 module을 호출하면서 1번의 read가 발생하고 이후에는 해당 데이터를 재사용하게 되어 속도가 개선될 수 있는 것이다. (I/O issue)

### 정리

오늘은 여러 가지 측면에서 부하테스트를 진행해보았다. 그리고 fastapi에 대해서도 배웠다. 실제로 load balance가 어떻게 이루어지는지 체험할 수 있어서 재미있었다. 아마 티케팅 사이트들도 이런 방식을 사용하고 있을 것이라는 추측을 해볼 수 있었다. (왜 그렇게 서버가 자꾸 멈추는지도..) fastapi를 배운 것은 api를 항상 받아만 왔었는데 이제는 내가 제공자가 될 수 있다는 생각이 들어서 재미있었다. 어떻게 활용할 수 있을지 고민해봐야 할 것 같다. 
